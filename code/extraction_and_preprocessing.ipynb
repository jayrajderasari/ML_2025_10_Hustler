{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-10T07:22:55.175740Z",
     "iopub.status.busy": "2025-04-10T07:22:55.175302Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('./Temp-Dataset'):\n",
    "    # for filename in filenames:\n",
    "    #     print(os.path.join(dirname, filename))\n",
    "    print(os.path.join(dirname))\n",
    "\n",
    "# You can write up to 20GB to the current directory (./) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "import pywt\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "\n",
    "# Define folder path\n",
    "folder_path = \"./Temp-Dataset/TRAIN/\"\n",
    "\n",
    "# Initialize lists for storing feature data\n",
    "fourier_features = []\n",
    "wavelet_features_list = []\n",
    "counter = 0\n",
    "lst = os.listdir(folder_path)\n",
    "\n",
    "# Iterate through all directories (persons) in the folder\n",
    "for person in lst:\n",
    "    person_path = os.path.join(folder_path, person)\n",
    "\n",
    "    # Ensure the path is a directory before proceeding\n",
    "    if not os.path.isdir(person_path):\n",
    "        continue  # Skip files that are not directories\n",
    "\n",
    "    for filename in os.listdir(person_path):\n",
    "        if filename.endswith(\".jpg\"):  # Process only image files\n",
    "            img_path = os.path.join(person_path, filename)\n",
    "            img = imread(img_path)\n",
    "            img = rgb2gray(img)\n",
    "            img = img.astype(np.float32)\n",
    "\n",
    "            # -------------------------------------------------------------\n",
    "            # Compute the 2D Fourier Transform (FFT)\n",
    "            # -------------------------------------------------------------\n",
    "            f_transform = np.fft.fft2(img)\n",
    "            f_shift = np.fft.fftshift(f_transform)  # Shift zero frequency to center\n",
    "            magnitude_spectrum = np.log(np.abs(f_shift) + 1)  # Log-scale for better visualization\n",
    "\n",
    "            # Extract FFT Features\n",
    "            fft_mean = np.mean(magnitude_spectrum)\n",
    "            fft_variance = np.var(magnitude_spectrum)\n",
    "            fft_energy = np.sum(np.abs(magnitude_spectrum) ** 2)\n",
    "\n",
    "            fourier_features.append({\n",
    "                'Person': person,\n",
    "                \"Image\": filename,\n",
    "                \"FFT Mean\": fft_mean,\n",
    "                \"FFT Variance\": fft_variance,\n",
    "                \"FFT Energy\": fft_energy\n",
    "            })\n",
    "\n",
    "            # -------------------------------------------------------------\n",
    "            # Compute a 2D Wavelet Transform (Haar wavelet)\n",
    "            # -------------------------------------------------------------\n",
    "            coeffs2 = pywt.dwt2(img, 'haar')\n",
    "            cA, (cH, cV, cD) = coeffs2\n",
    "\n",
    "            wavelet_features_list.append({\n",
    "                'Person': person,\n",
    "                \"Image\": filename,\n",
    "                \"cA Mean\": np.mean(cA), \"cA Variance\": np.var(cA), \"cA Energy\": np.sum(cA ** 2),\n",
    "                \"cH Mean\": np.mean(cH), \"cH Variance\": np.var(cH), \"cH Energy\": np.sum(cH ** 2),\n",
    "                \"cV Mean\": np.mean(cV), \"cV Variance\": np.var(cV), \"cV Energy\": np.sum(cV ** 2),\n",
    "                \"cD Mean\": np.mean(cD), \"cD Variance\": np.var(cD), \"cD Energy\": np.sum(cD ** 2)\n",
    "            })\n",
    "    \n",
    "    print(f'{person} has been extracted')\n",
    "    counter += 1\n",
    "    print(f'{counter},/ {len(lst)} completed.')\n",
    "\n",
    "# Convert lists to DataFrames\n",
    "fourier_df = pd.DataFrame(fourier_features)\n",
    "wavelet_df = pd.DataFrame(wavelet_features_list)\n",
    "\n",
    "# Save to Excel\n",
    "with pd.ExcelWriter(\"features_fourier_train.xlsx\") as writer:\n",
    "    fourier_df.to_excel(writer, sheet_name=\"Fourier Features train\", index=False)\n",
    "with pd.ExcelWriter(\"features_wavelet_train.xlsx\") as writer:\n",
    "    wavelet_df.to_excel(writer, sheet_name=\"Wavelet Features train\", index=False)\n",
    "print(\"Feature extraction completed. Data saved to features_fourier_train.xlsx and features_wavelet_train.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "import pywt\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "\n",
    "# Define folder path\n",
    "folder_path = \"./Temp-Dataset/TEST/\"\n",
    "\n",
    "# Initialize lists for storing feature data\n",
    "fourier_features = []\n",
    "wavelet_features_list = []\n",
    "counter = 0\n",
    "lst = os.listdir(folder_path)\n",
    "\n",
    "# Iterate through all directories (persons) in the folder\n",
    "for person in lst:\n",
    "    person_path = os.path.join(folder_path, person)\n",
    "\n",
    "    # Ensure the path is a directory before proceeding\n",
    "    if not os.path.isdir(person_path):\n",
    "        continue  # Skip files that are not directories\n",
    "\n",
    "    for filename in os.listdir(person_path):\n",
    "        if filename.endswith(\".jpg\"):  # Process only image files\n",
    "            img_path = os.path.join(person_path, filename)\n",
    "            img = imread(img_path)\n",
    "            img = rgb2gray(img)\n",
    "            img = img.astype(np.float32)\n",
    "\n",
    "            # -------------------------------------------------------------\n",
    "            # Compute the 2D Fourier Transform (FFT)\n",
    "            # -------------------------------------------------------------\n",
    "            f_transform = np.fft.fft2(img)\n",
    "            f_shift = np.fft.fftshift(f_transform)  # Shift zero frequency to center\n",
    "            magnitude_spectrum = np.log(np.abs(f_shift) + 1)  # Log-scale for better visualization\n",
    "\n",
    "            # Extract FFT Features\n",
    "            fft_mean = np.mean(magnitude_spectrum)\n",
    "            fft_variance = np.var(magnitude_spectrum)\n",
    "            fft_energy = np.sum(np.abs(magnitude_spectrum) ** 2)\n",
    "\n",
    "            fourier_features.append({\n",
    "                'Person': person,\n",
    "                \"Image\": filename,\n",
    "                \"FFT Mean\": fft_mean,\n",
    "                \"FFT Variance\": fft_variance,\n",
    "                \"FFT Energy\": fft_energy\n",
    "            })\n",
    "\n",
    "            # -------------------------------------------------------------\n",
    "            # Compute a 2D Wavelet Transform (Haar wavelet)\n",
    "            # -------------------------------------------------------------\n",
    "            coeffs2 = pywt.dwt2(img, 'haar')\n",
    "            cA, (cH, cV, cD) = coeffs2\n",
    "\n",
    "            wavelet_features_list.append({\n",
    "                'Person': person,\n",
    "                \"Image\": filename,\n",
    "                \"cA Mean\": np.mean(cA), \"cA Variance\": np.var(cA), \"cA Energy\": np.sum(cA ** 2),\n",
    "                \"cH Mean\": np.mean(cH), \"cH Variance\": np.var(cH), \"cH Energy\": np.sum(cH ** 2),\n",
    "                \"cV Mean\": np.mean(cV), \"cV Variance\": np.var(cV), \"cV Energy\": np.sum(cV ** 2),\n",
    "                \"cD Mean\": np.mean(cD), \"cD Variance\": np.var(cD), \"cD Energy\": np.sum(cD ** 2)\n",
    "            })\n",
    "    \n",
    "    print(f'{person} has been extracted')\n",
    "    counter += 1\n",
    "    print(f'{counter},/ {len(lst)} completed.')\n",
    "\n",
    "# Convert lists to DataFrames\n",
    "fourier_df = pd.DataFrame(fourier_features)\n",
    "wavelet_df = pd.DataFrame(wavelet_features_list)\n",
    "\n",
    "# Save to Excel\n",
    "with pd.ExcelWriter(\"features_fourier_test.xlsx\") as writer:\n",
    "    fourier_df.to_excel(writer, sheet_name=\"Fourier Features test\", index=False)\n",
    "with pd.ExcelWriter(\"features_wavelet_test.xlsx\") as writer:\n",
    "    wavelet_df.to_excel(writer, sheet_name=\"Wavelet Features test\", index=False)\n",
    "\n",
    "print(\"Feature extraction completed. Data saved to features_fourier_test.xlsx and features_wavelet_test.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Excel file (Update the file path as needed)\n",
    "file_path = \"./features_wavelet_train.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Extract Image ID\n",
    "\n",
    "image_ids = df['Image']  # Assuming 'Image' column contains the image IDs\n",
    "\n",
    "# Extract relevant columns for PCA\n",
    "mean_features = df[['cA Mean', 'cH Mean', 'cV Mean', 'cD Mean']]\n",
    "variance_features = df[['cA Variance', 'cH Variance', 'cV Variance', 'cD Variance']]\n",
    "energy_features = df[['cA Energy', 'cH Energy', 'cV Energy', 'cD Energy']]\n",
    "\n",
    "# Function to apply PCA\n",
    "def apply_pca(data, n_components=2):\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    \n",
    "    pca = PCA(n_components=n_components)\n",
    "    transformed_data = pca.fit_transform(data_scaled)\n",
    "    \n",
    "    explained_variance = np.sum(pca.explained_variance_ratio_)\n",
    "    return transformed_data, explained_variance\n",
    "\n",
    "# Apply PCA by feature type\n",
    "pca_mean, var_mean = apply_pca(mean_features)\n",
    "pca_variance, var_variance = apply_pca(variance_features)\n",
    "pca_energy, var_energy = apply_pca(energy_features)\n",
    "\n",
    "# Store explained variance results\n",
    "print(f\"Explained Variance:\")\n",
    "print(f\"Mean Features: {var_mean * 100:.2f}%\")\n",
    "print(f\"Variance Features: {var_variance * 100:.2f}%\")\n",
    "print(f\"Energy Features: {var_energy * 100:.2f}%\")\n",
    "\n",
    "# Create a DataFrame to store PCA results with Image ID\n",
    "pca_df = pd.DataFrame({\n",
    "    'Image': image_ids,  # Add Image ID column\n",
    "    'Person': df['Person'],  # Add Person column\n",
    "    'PCA_Mean_1': pca_mean[:, 0],\n",
    "    'PCA_Mean_2': pca_mean[:, 1],\n",
    "    'PCA_Variance_1': pca_variance[:, 0],\n",
    "    'PCA_Variance_2': pca_variance[:, 1],\n",
    "    'PCA_Energy_1': pca_energy[:, 0],\n",
    "    'PCA_Energy_2': pca_energy[:, 1],\n",
    "})\n",
    "\n",
    "# Define output file path\n",
    "output_file_path = \"pca_wavelet_features_train.xlsx\"\n",
    "\n",
    "# Save to Excel\n",
    "pca_df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"PCA results saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Excel file (Update the file path as needed)\n",
    "file_path = \"./features_wavelet_test.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Extract Image ID\n",
    "image_ids = df['Image']  # Assuming 'Image' column contains the image IDs\n",
    "\n",
    "# Extract relevant columns for PCA\n",
    "mean_features = df[['cA Mean', 'cH Mean', 'cV Mean', 'cD Mean']]\n",
    "variance_features = df[['cA Variance', 'cH Variance', 'cV Variance', 'cD Variance']]\n",
    "energy_features = df[['cA Energy', 'cH Energy', 'cV Energy', 'cD Energy']]\n",
    "\n",
    "# Function to apply PCA\n",
    "def apply_pca(data, n_components=2):\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    \n",
    "    pca = PCA(n_components=n_components)\n",
    "    transformed_data = pca.fit_transform(data_scaled)\n",
    "    \n",
    "    explained_variance = np.sum(pca.explained_variance_ratio_)\n",
    "    return transformed_data, explained_variance\n",
    "\n",
    "# Apply PCA by feature type\n",
    "pca_mean, var_mean = apply_pca(mean_features)\n",
    "pca_variance, var_variance = apply_pca(variance_features)\n",
    "pca_energy, var_energy = apply_pca(energy_features)\n",
    "\n",
    "# Store explained variance results\n",
    "print(f\"Explained Variance:\")\n",
    "print(f\"Mean Features: {var_mean * 100:.2f}%\")\n",
    "print(f\"Variance Features: {var_variance * 100:.2f}%\")\n",
    "print(f\"Energy Features: {var_energy * 100:.2f}%\")\n",
    "\n",
    "# Create a DataFrame to store PCA results with Image ID\n",
    "pca_df = pd.DataFrame({\n",
    "    'Image': image_ids,  # Add Image ID column\n",
    "    'Person': df['Person'],  # Add Person column\n",
    "    'PCA_Mean_1': pca_mean[:, 0],\n",
    "    'PCA_Mean_2': pca_mean[:, 1],\n",
    "    'PCA_Variance_1': pca_variance[:, 0],\n",
    "    'PCA_Variance_2': pca_variance[:, 1],\n",
    "    'PCA_Energy_1': pca_energy[:, 0],\n",
    "    'PCA_Energy_2': pca_energy[:, 1],\n",
    "})\n",
    "\n",
    "# Define output file path\n",
    "output_file_path = \"pca_wavelet_features_test.xlsx\"\n",
    "\n",
    "# Save to Excel\n",
    "pca_df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"PCA results saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- Step 1: Load Excel Data ---\n",
    "# Load the dataset from the Excel file\n",
    "file_path = \"./pca_wavelet_features_train.xlsx\"  # Replace with your actual file path\n",
    "data_df = pd.read_excel(file_path)\n",
    "\n",
    "# Extract numeric columns and their names\n",
    "data = data_df.select_dtypes(include=[\"number\"])  # Select only numeric columns\n",
    "feature_names = data.columns  # Update feature names to match numeric columns\n",
    "\n",
    "data = data.fillna(0)\n",
    "\n",
    "# Convert to a NumPy array\n",
    "data = data.values\n",
    "\n",
    "# --- Step 2: Compute Feature Similarity ---\n",
    "# Convert data to a PyTorch tensor\n",
    "data_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "# Normalize the data along the feature axis\n",
    "data_tensor_n = F.normalize(data_tensor, p=2, dim=0)  # Normalize columns (features)\n",
    "\n",
    "# Compute a similarity matrix (dot product of normalized features)\n",
    "similarity_matrix = data_tensor_n.T @ data_tensor_n  # Shape: (num_features, num_features)\n",
    "\n",
    "# --- Step 3: Rank Features ---\n",
    "# For each feature, rank other features based on similarity\n",
    "ranked_features = {}\n",
    "for i, feature in enumerate(feature_names):\n",
    "    # Get similarity scores for the current feature\n",
    "    scores = similarity_matrix[i].numpy()\n",
    "    \n",
    "    # Rank features by descending similarity\n",
    "    sorted_indices = scores.argsort()[::-1]  # Descending order\n",
    "    ranked_features[feature] = [(feature_names[j], scores[j]) for j in sorted_indices]\n",
    "\n",
    "# --- Step 4: Save Ranked Features ---\n",
    "# Prepare data for saving\n",
    "output_data = []\n",
    "for feature, rankings in ranked_features.items():\n",
    "    for rank, (other_feature, score) in enumerate(rankings, start=1):\n",
    "        output_data.append([feature, rank, other_feature, score])\n",
    "\n",
    "# Create a DataFrame for the ranked features\n",
    "output_df = pd.DataFrame(output_data, columns=[\"Feature\", \"Rank\", \"Ranked Feature\", \"Score\"])\n",
    "\n",
    "# Save the ranked features to a new Excel file\n",
    "output_file = \"ranked_features_pca_wavelet.xlsx\"\n",
    "output_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Feature ranking completed. Results saved to '{output_file}'.\")\n",
    "\n",
    "\n",
    "# Pivot the similarity scores into a matrix for heatmap\n",
    "heatmap_data = output_df.pivot(index=\"Feature\", columns=\"Ranked Feature\", values=\"Score\")\n",
    "\n",
    "# Set up the figure size\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create the heatmap\n",
    "sns.heatmap(heatmap_data, cmap=\"coolwarm\", center=0, square=True, linewidths=0.5)\n",
    "\n",
    "# Title and display\n",
    "plt.title(\"Feature Similarity Heatmap (Cosine Similarity)\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7089990,
     "sourceId": 11334279,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
